\section{Absorbing Boundary Conditions}
\label{sec:transparent_bc}
When simulating a wave a classical example of a domain on which to do so is a \textit{wave guide}, a rectangular domain through which the 
wave is propagated. Since we restrict ourselves to the 1d case in this thesis, trivially every domain interval we can choose corresponds to 
a sort of waveguide. We are interested in simulating a wave propagating through this waveguide. 
Lets say we want to send a wave through the waveguide from left to right. We can achieve this by imposing 
a corresponding Dirichlet or Neumann boundary condition at the point of entry. A question arises: \\ \\
\textit{What boundary condition should be imposed at the upper boundary?} \\ \\
The answer may differ depending on the purpose of the simulation. The problem with using a simple Dirichlet or Neumann boundary condition at the upper boundary
as well is that the incident wave is directly influenced and modified by the upper boundary condition. 
Lets say we impose a Dirichlet boundary condition at the lower boundary and a homogeneous Neumann boundary condition at the upper boundary
\begin{equation*}
    u(0, t) = \sin(x-t),  \qquad u_x(L,t) = 0,
\end{equation*}  
then the upper boundary will reflect the full wave back. This clearly pollutes the incident wave and if we wanted to observe how the the incident wave changes 
by passing through an inhomogeneous medium, the reflected wave would overshadow any slight modulation stemming from variations in the material.
In reality in this context it would be more interesting to simulate the problem on an unbounded domain. We would like the wave to just propagate through the upper boundary
and not return. We could achieve this by choosing a very large domain, large enough such that the incident wave never reaches the upper boundary for $t \in [0,T]$.
Clearly this is a suboptimal, since we increase computaional load needlessly, the majority of the simulated wave would be uninteresting. 
In practice it is more convenient to choose an artifical boundary.
To simulate an artificial boundary of this kind we need to impose artificial boundary conditions, these are often called \textit{absorbing-, transparent-,} or 
\textit{non-reflecting} boundary conditions. \\
Suppose
\begin{equation*}
    \text{supp}(f),\text{supp}(c) \subset \Omega \times [0,T],
\end{equation*}
i.e.\ the artificial boundary has been chosen sufficiently far away from the origin, such that the wave outside 
of the domain travels at a constant speed $\sqrt{c} = 1$ with no forcing. \\
Secondly assume that no waves are returning from outside of the domain, meaning all the waves outside 
the domain travel soley towards infinity.
By d'Alembert we find that the solution outside the domain is of the form
\begin{equation*}
    u(x,t) = \psi(x-t) \qquad \text{for }x > L, t \in [0,T],
\end{equation*}
where $\psi \in C^1((L,\infty))$ only depends on the incident wave.
This yields the (exact) first order absorbing boundary condition 
\begin{equation}
    \label{eq:absorbing_bc}
    u_t + u_x = 0
\end{equation}
at the upper boundary (exit of the waveguide), which corresponds to 
\begin{equation*}
    u_t(L, \cdot) + u_x(L,\cdot) = 0 \qquad \text{in } [0, T].
\end{equation*}

To implement this boundary condition into our time-marching scheme we have to first treat the bilinear form $b$ at the upper boundary as if we were to implement 
a Neumann boundary condition (see section \ref{sec:boundary_conditions_elliptic}), meaning after integrating by parts and summing over all elements we don't introduce
the symmetry and penalty terms at the corresponding node $x_{N+1}$, instead we apply the absorbing boundary condition and get
\begin{equation*}
    -\avg{\underbrace{c(x_{N+1},t)}_{=1} \partial_x u_h(x_{N+1},t)}\jump{v(x_{N+1})} = \avg{ \partial_t u_h(x_{N+1},t) } \jump{v(x_{N+1})}.
\end{equation*}

the semi-discrete scheme (\ref{eq:wave_semidiscrete_var_form}) turns into
\begin{equation*}
    (\partial_{t}^2 u_h(t), v)_{L^2(\Omega)} + b_h(u_h,v;t) + \avg{\partial_t u_h(x_{N+1},t) } \jump{v(x_{N+1})} = \ell_h (v;t) 
    \qquad \forall v \in V_h, t \in [0,T],
\end{equation*}
where 
\begin{align*}
    b_h(u,v;t) & = \sum_{n=0}^N \int_{I_n} c(x,t)u_x(x,t)v_x(x)\, \text{d}x
		-\sum_{n=0}^{N} \avg{c(x_n,t)u_x(x_n, t)}\jump{v(x_n)} + \avg{c(x_n,t)v_x(x_n)}\jump{u(x_n,t)} \\
		& + \sum_{n=0}^{N} \texttt{a}_n(t)\jump{u(x_n,t)}\jump{v(x_n)},                                   \\
		\ell(v;t)  & = (f(t),v)_{L^2(\Omega)}+ g_0(t)c(x_0^+,t)v_x(x_0^+) 
	    + \texttt{a}_0(t) g_0(t) v(x_{0}^+)
\end{align*}
are slightly modified. \\
And the semi-discrete matrix-vector system becomes
\begin{equation*}
     \textbf{M} \ddot{\mathbf{u}}(t) + \mathbf{B}(t)\mathbf{u}(t) + \mathbf{R}(t)\dot{\mathbf{u}}(t) = \mathbf{l}(t) \qquad \forall t \in  [0,T],
\end{equation*}
where $[\mathbf{R}(t)]_{i,j} = \avg{\Phi_j(x_{N+1},t) } \jump{\Phi_i(x_{N+1})} $ is a matrix where the only non-zero entry is the one at the bottom right corner
where $i = j = \text{dim}(V_h)$ and $\Phi_i$ the basis centered at $x_{N+1}$ is.
\\ \\
From here on we can use a (second order) centered finite difference to approximate  
\begin{equation*}
    \dot{\mathbf{u}}(t) \approx \frac{\mathbf{u}(t + \Delta t) - 
    \mathbf{u}(t - \Delta t)}{2 \Delta t} 
\end{equation*}
and similarly as before we find the slightly modified, fully-discrete leapfrog scheme
\begin{equation*}
    \Big(\mathbf{M} + \frac{\Delta t}{2}\mathbf{R}_m\Big) \mathbf{u}_{m+1} = \Delta t^2 \mathbf{l}_m + (2 \mathbf{M} - \Delta t^2 \mathbf{B}_m) \mathbf{u}_{m} 
    + \Big(\frac{\Delta t}{2}\mathbf{R}_m - \mathbf{I}\Big) \mathbf{u}_{m-1}.
\end{equation*}
We have to also make a slight adjustment to the initialization of the solution at the first time-step $\mathbf{u}_1$. By using a Taylor-expansion and 
the semi-discrete scheme we have just derived we can define
\begin{equation*}
    \mathbf{u}_1 :=   \mathbf{u}_0 + \Delta t \mathbf{v}_0 + 
    \frac{\Delta t^2}{2}\mathbf{M}^{-1}( \mathbf{l}_0 - \mathbf{B}_0 \mathbf{u}_0 - \mathbf{R}_0 \mathbf{v}_0).
\end{equation*}  


\section{Updating the Stiffness Matrix}
By definition the bilinear form $b_h$ and by extension the stiffness matrix $\mathbf{B}(t)$ are time dependent. A priori this means that the matrix $\mathbf{B}_m$ has to be completely reassembled
in each timestep $t_m = m\Delta t$. This is very costly, in fact the assembly of the stiffness matrix is by far the most expensive operation and the source of the heaviest computational load.
Luckily there is room for optimization. We note that the time-dependency solely comes from the coefficient $c$ in the bilinear form $b_h$, therefore if the coefficient satisfies 
certain conditions we can simplify the assembly of $\mathbf{B}_m$.
\subsubsection{Time-Independent Coefficient}
If $c$ is in fact only a function of space and not of time, meaning $c(x,t) = c(x,0)$ for all $t \in [0,T]$, then we don't have to update the stiffness matrix at all since
\begin{equation*}
    \mathbf{B}_m = \mathbf{B}_0 \qquad \forall m.
\end{equation*}

\subsubsection{Space-Independent Coefficient}
Similarly we can also consider the case of spatially independent coefficients. If $c(x,t) = c(0, t)$ for all $x \in \Omega, t \in [0,T]$ then we can write $c(0,t) = c(t)$ and  
\begin{align*}
    b_h(\Phi_j, \Phi_i;t) = c(t)\Big( 
        \sum_{n=0}^N \int_{I_n} \Phi_i^{\prime} \Phi_j^{\prime}\, \text{d}x
        -\sum_{n=0}^{N+1} \avg{ \Phi_j^{\prime}(x_n) }\jump{\Phi_i(x_n)} + \avg{ \Phi_i^{\prime}(x_n) }\jump{ \Phi_j(x_n) } 
        + \sum_{n=0}^{N+1} \frac{\sigma}{\texttt{h}_n} \jump{ \Phi_j(x_n) }\jump{\Phi_j(x_n)}
        \Big).
\end{align*}
We can therefore write 
\begin{equation}
    \mathbf{B}_m = \frac{c(t)}{c(0)} \mathbf{B}_0,        \nonumber
\end{equation}

which allows for a fast vectorized update.

\subsubsection{Piecewise Constant Coefficient}
Following a similar logic as in the space-independent case we can consider a coefficient $c$ which is piecewise constant in space and arbitrary in time.
Let $y_1,\ldots,y_{M} \in \Omega$ and $y_0 = 0$ denote the lower boundary and $y_{M+1} = 1$ the upper boundary of $\Omega$.
Define the open intervals
\begin{equation*}
    R_i := (y_i, y_{i+1}) \qquad \text{for } i \in \{0,\ldots,M\}
\end{equation*}
and the in space piecewise constant coefficient 
\begin{equation*}
    c(x,t) := 
    \begin{cases}
        \rho_0(t) & \text{for } x \in R_0 \\
        \rho_1(t) & \text{for } x \in R_1 \\
        \vdots \\
        \rho_M(t) & \text{for } x \in R_M
    \end{cases},
\end{equation*}
where $t \in [0,T]$ and 
\begin{equation*}
    c_{\min} \leq \rho_i(t) \leq c_{\max} \qquad \forall i \in \{0,\ldots,M\}, t \in [0,T].
\end{equation*}
The update method could work in this fashion for any type functions $\rho_i$, but we will only consider  $\rho_i \in C^{\infty}$.
Now to properly model the discontinuous coefficient using the DG-FEM we require that the mesh is chosen in such a way that the discontinuities never occur inside an element but rather 
only at the boundary. If $\mathcal{T}_h = \{I_n\}_{n=0}^N$ denotes the partition of $\Omega$, where $I_n = (x_n, x_{n+1})$ are the elements defined by the face nodes $0 = x_0,\ldots,x_{N+1}=1$,
then we require 
\begin{equation*}
    \{y_0,\ldots,y_{M+1}\} \subset \{x_0,\ldots,x_{N+1}\}.
\end{equation*} 

Recall that in the assembly of the stiffness matrix (see \ref{sec:stiff_assembly}) we had 
\begin{equation*}
    \mathbf{B}(t) = \mathbf{A}(t) - \mathbf{B}_{\text{cons}}(t) + \mathbf{B}_{\text{penal}}(t).
\end{equation*}
We update all three matrices separately.
We start by updating $\mathbf{A}$, which proves to be the simplest case. \\
We were able to characterize the assembly of each of the sub-matrices by using local contribution matrices
for each element (in the case of $\mathbf{A}$) or for each face node (in the case of $\mathbf{B}_{\text{cons}}, \mathbf{B}_{\text{penal}}$).
Fix a subdomain index $ m\in \{0,\ldots,M\} $ and let $n\in \{0,\ldots,N\} $ such that $I_n \subset R_m$ is an element contained in the subdomain. 
The local contribution matrix of $\mathbf{A}$ for the element $I_n$ was given by 
\begin{equation*}
    [\widehat{\mathbf{A}}^{(n)}(t)]_{i,j} = \frac{2}{h_s} \int_{-1}^1 c(F_s(\xi),t) \, \widehat{\phi}_j^{\, \prime}(\xi) \widehat{\phi}_i^{\, \prime}(\xi) \, \text{d}\xi
    = \frac{2\rho_{m}(t)}{h_s} \int_{-1}^1 \, \widehat{\phi}_j^{\, \prime}(\xi) \widehat{\phi}_i^{\, \prime}(\xi) \, \text{d}\xi
\end{equation*}

\newpage
Let $ R_1,\ldots, R_M \subset \Omega $ be closed, pairwise disjoint intervals for some $M \in \N$ and denote 
\begin{equation*}
     R_0 := \Omega \setminus \bigcup_{i = 1}^{M} R_i
\end{equation*} 
the background medium.
Define the piecewise constant coefficient in space as 
\begin{equation*}
    c(x,t) := 
    \begin{cases}
        \rho_0(t) & \text{for } x \in R_0 \\
        \rho_1(t) & \text{for } x \in R_1 \\
        \vdots \\
        \rho_M(t) & \text{for } x \in R_M
    \end{cases},
\end{equation*}
where $t \in [0,T]$ and 
\begin{equation*}
    c_{\min} \leq \rho_i(t) \leq c_{\max} \qquad \forall i \in \{0,\ldots,M\}, t \in [0,T].
\end{equation*}
The update method could work in this fashion for any type functions $\rho_i$, but we will only consider  $\rho_i \in C^{\infty}$.
We will only require this specific setup where the resonators $R_i$ for $i \in \{1,\ldots,M\}$ are closed, pairwise disjoint intervals, it is not hard to see
how the entire procedure can be generalized 
Recall that in the assembly of the stiffness matrix (see \ref{sec:stiff_assembly}) we had 
\begin{equation*}
    \mathbf{B} = \mathbf{A} - \mathbf{B}_{\text{cons}} + \mathbf{B}_{\text{penal}}.
\end{equation*}
We will update all three matrices separately. 